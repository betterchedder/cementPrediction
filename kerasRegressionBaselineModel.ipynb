{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Strength'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Blast Furnace Slag', 'Cement', 'Coarse Aggregate', 'Fine Aggregate', 'Fly Ash', 'Strength', 'Superplasticizer', 'Water']\n"
     ]
    }
   ],
   "source": [
    "df_cement = pd.read_csv('concrete_data.csv')\n",
    "\n",
    "print(sorted(list(df_cement)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a features and target dataframe, where df_features does not contain target variable and df_target contains only target variable\n",
    "df_features = df_cement.drop(target_variable, axis=1)\n",
    "\n",
    "df_target = df_cement[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain split data in dataframe format, by sending df_features and df_target to helper function\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(df_features, df_target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (df_features_train.shape[1],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Single hidden layer, \n",
    "model.add(Dense(10, input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 254946.6250 - mse: 254946.6250\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 551us/step - loss: 122610.0547 - mse: 122610.0547\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 877us/step - loss: 51571.5625 - mse: 51571.5625\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 614us/step - loss: 19392.4785 - mse: 19392.4785\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 445us/step - loss: 7612.3364 - mse: 7612.3364\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 452us/step - loss: 4175.9004 - mse: 4175.9004\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 415us/step - loss: 3405.3184 - mse: 3405.3184\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 453us/step - loss: 3219.9653 - mse: 3219.9653\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 448us/step - loss: 3123.3159 - mse: 3123.3159\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 431us/step - loss: 3026.0469 - mse: 3026.0469\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 441us/step - loss: 2932.0708 - mse: 2932.0708\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 524us/step - loss: 2836.2383 - mse: 2836.2383\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 458us/step - loss: 2742.9609 - mse: 2742.9609\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 423us/step - loss: 2649.2388 - mse: 2649.2388\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 463us/step - loss: 2559.5593 - mse: 2559.5593\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 443us/step - loss: 2470.1084 - mse: 2470.1084\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 434us/step - loss: 2384.2891 - mse: 2384.2891\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 434us/step - loss: 2301.1526 - mse: 2301.1526\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 430us/step - loss: 2221.2031 - mse: 2221.2031\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 422us/step - loss: 2146.5098 - mse: 2146.5098\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 448us/step - loss: 2067.2705 - mse: 2067.2705\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 451us/step - loss: 1997.9980 - mse: 1997.9980\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 427us/step - loss: 1927.8842 - mse: 1927.8842\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 448us/step - loss: 1864.2991 - mse: 1864.2991\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 429us/step - loss: 1800.2290 - mse: 1800.2290\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 425us/step - loss: 1742.1757 - mse: 1742.1757\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 496us/step - loss: 1683.2054 - mse: 1683.2054\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 432us/step - loss: 1630.4019 - mse: 1630.4019\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 506us/step - loss: 1580.6967 - mse: 1580.6967\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 471us/step - loss: 1530.6051 - mse: 1530.6051\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 641us/step - loss: 1484.4615 - mse: 1484.4615\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1442.2706 - mse: 1442.2706\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1400.2133 - mse: 1400.2133\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 458us/step - loss: 1362.4409 - mse: 1362.4409\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 443us/step - loss: 1323.5741 - mse: 1323.5741\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 436us/step - loss: 1290.6808 - mse: 1290.6808\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 428us/step - loss: 1255.9875 - mse: 1255.9875\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 433us/step - loss: 1225.2086 - mse: 1225.2086\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 424us/step - loss: 1194.6483 - mse: 1194.6483\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 430us/step - loss: 1165.1414 - mse: 1165.1414\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 454us/step - loss: 1138.3549 - mse: 1138.3549\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 551us/step - loss: 1113.2795 - mse: 1113.2795\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 435us/step - loss: 1087.9941 - mse: 1087.9941\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 439us/step - loss: 1065.0123 - mse: 1065.0123\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 440us/step - loss: 1046.8602 - mse: 1046.8602\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 416us/step - loss: 1021.6840 - mse: 1021.6840\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 499us/step - loss: 1000.6061 - mse: 1000.6061\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 435us/step - loss: 981.7232 - mse: 981.7232\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 419us/step - loss: 963.7577 - mse: 963.7577\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 421us/step - loss: 944.9585 - mse: 944.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x288fe63d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_features_train, df_target_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 563us/step - loss: 1049.7830 - mse: 1049.7830\n",
      "1049.782958984375\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x=df_features_test, y=df_target_test, return_dict=True)\n",
    "print(results['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain Model Split and Train 50 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 545us/step - loss: 137.3782 - mse: 137.3782\n",
      "10/10 [==============================] - 0s 531us/step - loss: 153.9442 - mse: 153.9442\n",
      "10/10 [==============================] - 0s 537us/step - loss: 493.2881 - mse: 493.2881\n",
      "10/10 [==============================] - 0s 529us/step - loss: 1476.9911 - mse: 1476.9911\n",
      "10/10 [==============================] - 0s 557us/step - loss: 654.7052 - mse: 654.7052\n",
      "10/10 [==============================] - 0s 574us/step - loss: 132.2951 - mse: 132.2951\n",
      "10/10 [==============================] - 0s 559us/step - loss: 898.7112 - mse: 898.7112\n",
      "10/10 [==============================] - 0s 540us/step - loss: 529.1634 - mse: 529.1634\n",
      "10/10 [==============================] - 0s 528us/step - loss: 108.1302 - mse: 108.1302\n",
      "10/10 [==============================] - 0s 660us/step - loss: 426.2629 - mse: 426.2629\n",
      "10/10 [==============================] - 0s 524us/step - loss: 181.7560 - mse: 181.7560\n",
      "10/10 [==============================] - 0s 571us/step - loss: 153.6268 - mse: 153.6268\n",
      "10/10 [==============================] - 0s 613us/step - loss: 181.6824 - mse: 181.6824\n",
      "10/10 [==============================] - 0s 543us/step - loss: 169.2698 - mse: 169.2698\n",
      "10/10 [==============================] - 0s 558us/step - loss: 217.2445 - mse: 217.2445\n",
      "10/10 [==============================] - 0s 580us/step - loss: 172.9962 - mse: 172.9962\n",
      "10/10 [==============================] - 0s 563us/step - loss: 100.1126 - mse: 100.1126\n",
      "10/10 [==============================] - 0s 539us/step - loss: 228.2460 - mse: 228.2460\n",
      "10/10 [==============================] - 0s 541us/step - loss: 148.4787 - mse: 148.4787\n",
      "10/10 [==============================] - 0s 550us/step - loss: 96.9398 - mse: 96.9398\n",
      "10/10 [==============================] - 0s 582us/step - loss: 1273.1230 - mse: 1273.1230\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 312.4066 - mse: 312.4066\n",
      "10/10 [==============================] - 0s 543us/step - loss: 153.9083 - mse: 153.9083\n",
      "10/10 [==============================] - 0s 519us/step - loss: 101.8891 - mse: 101.8891\n",
      "10/10 [==============================] - 0s 569us/step - loss: 1223.2114 - mse: 1223.2114\n",
      "10/10 [==============================] - 0s 584us/step - loss: 104.1371 - mse: 104.1371\n",
      "10/10 [==============================] - 0s 550us/step - loss: 104.1141 - mse: 104.1141\n",
      "10/10 [==============================] - 0s 500us/step - loss: 193.5245 - mse: 193.5245\n",
      "10/10 [==============================] - 0s 550us/step - loss: 109.3464 - mse: 109.3464\n",
      "10/10 [==============================] - 0s 542us/step - loss: 184.9957 - mse: 184.9957\n",
      "10/10 [==============================] - 0s 515us/step - loss: 113.8010 - mse: 113.8010\n",
      "10/10 [==============================] - 0s 552us/step - loss: 179.5338 - mse: 179.5338\n",
      "10/10 [==============================] - 0s 528us/step - loss: 1429.3131 - mse: 1429.3131\n",
      "10/10 [==============================] - 0s 517us/step - loss: 159.3842 - mse: 159.3842\n",
      "10/10 [==============================] - 0s 543us/step - loss: 104.1172 - mse: 104.1172\n",
      "10/10 [==============================] - 0s 632us/step - loss: 1082.5341 - mse: 1082.5341\n",
      "10/10 [==============================] - 0s 541us/step - loss: 474.7842 - mse: 474.7842\n",
      "10/10 [==============================] - 0s 827us/step - loss: 193.0934 - mse: 193.0934\n",
      "10/10 [==============================] - 0s 522us/step - loss: 240.5360 - mse: 240.5360\n",
      "10/10 [==============================] - 0s 532us/step - loss: 576.2393 - mse: 576.2393\n",
      "10/10 [==============================] - 0s 495us/step - loss: 146.1456 - mse: 146.1456\n",
      "10/10 [==============================] - 0s 550us/step - loss: 124.0766 - mse: 124.0766\n",
      "10/10 [==============================] - 0s 536us/step - loss: 127.9660 - mse: 127.9660\n",
      "10/10 [==============================] - 0s 530us/step - loss: 122.3758 - mse: 122.3758\n",
      "10/10 [==============================] - 0s 529us/step - loss: 117.9552 - mse: 117.9552\n",
      "10/10 [==============================] - 0s 508us/step - loss: 140.5104 - mse: 140.5104\n",
      "10/10 [==============================] - 0s 550us/step - loss: 323.3795 - mse: 323.3795\n",
      "10/10 [==============================] - 0s 538us/step - loss: 331.2221 - mse: 331.2221\n",
      "10/10 [==============================] - 0s 541us/step - loss: 493.8952 - mse: 493.8952\n",
      "10/10 [==============================] - 0s 526us/step - loss: 303.4855 - mse: 303.4855\n"
     ]
    }
   ],
   "source": [
    "ls_mse_values = []\n",
    "\n",
    "for iteration in range(0, 50):\n",
    "    #Obtain split data in dataframe format, by sending df_features and df_target to helper function\n",
    "    df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(df_features, df_target, test_size=0.3)\n",
    "\n",
    "    # Create a features and target dataframe, where df_features does not contain target variable and df_target contains only target variable\n",
    "    df_features = df_cement.drop(target_variable, axis=1)\n",
    "\n",
    "    df_target = df_cement[target_variable]\n",
    "\n",
    "    #Obtain split data in dataframe format, by sending df_features and df_target to helper function\n",
    "    df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(df_features, df_target, test_size=0.3)\n",
    "\n",
    "    input_shape = (df_features_train.shape[1],)\n",
    "\n",
    "    #Create Model\n",
    "    model = Sequential()\n",
    "    #Single hidden layer, \n",
    "    model.add(Dense(10, input_shape=input_shape, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "    model.fit(df_features_train, df_target_train, epochs=50, verbose=0)\n",
    "\n",
    "    results = model.evaluate(x=df_features_test, y=df_target_test, return_dict=True)\n",
    "\n",
    "    ls_mse_values.append(results['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mean and Standard Deviations of 50 Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 50 runs, the mean MSE is 344.12 with a standard deviation of 361.04\n"
     ]
    }
   ],
   "source": [
    "avg_mse = np.mean(np.array(ls_mse_values))\n",
    "std_dev_mse = np.std(np.array(ls_mse_values))\n",
    "\n",
    "print(\"For the 50 runs, the mean MSE is {:.2f} with a standard deviation of {:.2f}\".format(avg_mse, std_dev_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mehltrej",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
